{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "#from keras.datasets import cifar10\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "#model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend import set_session,tensorflow_backend\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list=\"0\"))\n",
    "#allow_growth=True: 利用量に合わせてGPUのメモリを動的確保(ちょっとだけ遅くなるけどignorable)\n",
    "#visible_device_list=\"0,1,2,3\": 利用するGPUのdevice番号を(何故か文字列で)指定する．他の人と被らないようにする．\n",
    "\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2 # 上限を0.2に抑える(optional)\n",
    "set_session(tf.Session(config=config))\n",
    "#top_model_weights_path = 'fc_model.h5'\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "data_augmentation = False\n",
    "#num_predictions = 2\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_food_trained_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 224, 224, 3)\n",
      "(924, 1)\n",
      "(236, 224, 224, 3)\n",
      "(236, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob2\n",
    "import re\n",
    "import os.path\n",
    "#import os\n",
    "\n",
    "def getGTfromPath(path):\n",
    "    label = os.path.dirname(path).split('/')[-1]\n",
    "    if label == 'food':\n",
    "        return [1]\n",
    "    return [0]\n",
    "def loadImage(path, target_size=(224,224,3)):\n",
    "    img = cv2.imread(path)\n",
    "    return np.resize(img,target_size)\n",
    "\n",
    "train_filelist = glob2.glob('./data/train/*/*.png')\n",
    "y_train = [getGTfromPath(p) for p in train_filelist]\n",
    "x_train = [loadImage(p) for p in train_filelist]\n",
    "#print(y_train[0:10])\n",
    "\n",
    "test_filelist = glob2.glob('./data/test/*/*.png')\n",
    "x_test = [loadImage(p) for p in test_filelist]\n",
    "y_test = [getGTfromPath(p) for p in test_filelist]\n",
    "\n",
    "'''\n",
    "#train_filelist2 = os.listdir('./data/train/nofood/')\n",
    "print(sorted(train_filelist1)[0])\n",
    "test_filelist1 = os.listdir('./data/test/food')\n",
    "test_filelist2 = os.listdir('./data/test/nofood/')\n",
    "\n",
    "train_imglist1 = []\n",
    "train_imglist2 = []\n",
    "\n",
    "test_imglist1 = []\n",
    "test_imglist2 = []\n",
    "\n",
    "train_tag1 = []\n",
    "train_tag2 = []\n",
    "\n",
    "test_tag1 = []\n",
    "test_tag2 = []\n",
    "\n",
    "for train_imgpath0 in train_filelist1:\n",
    "    train_imgpath1 = os.path.join('./data/train/food/', train_imgpath0)\n",
    "    train_img1 = cv2.imread(train_imgpath1)\n",
    "    train_imglist1.append(np.resize(train_img1,(224,224,3)))\n",
    "#for train_imgpath3 in train_filelist2:\n",
    "    #train_imgpath2 = os.path.join('./data/train/nofood',train_imgpath3)\n",
    "    #train_img2 = cv2.imread(train_imgpath2)\n",
    "    #train_imglist2.append(np.resize(train_img2,(224,224,3)))\n",
    "    \n",
    "for test_imgpath0 in test_filelist1:\n",
    "    test_imgpath1 = os.path.join('./data/train/food/', test_imgpath0)\n",
    "    test_img1 = cv2.imread(test_imgpath1)\n",
    "    test_imglist1.append(np.resize(test_img1,(224,224,3)))\n",
    "#for test_imgpath3 in test_filelist2:\n",
    "    #test_imgpath2 = os.path.join('./data/train/nofood',test_imgpath3)\n",
    "    #test_img2 = cv2.imread(test_imgpath2)\n",
    "    #test_imglist2.append(np.resize(test_img2,(224,224,3)))\n",
    "    \n",
    "    \n",
    "train_tag1 = [1]*len(train_filelist1)#food\n",
    "train_tag2 = [0]*len(train_filelist2)#nofood\n",
    "\n",
    "test_tag1 = [1]*len(test_filelist1)#food\n",
    "test_tag2 = [0]*len(test_filelist2)#nofood\n",
    "\n",
    "#x_train = [imglist1, imglist2]\n",
    "train_imglist1 = train_imglist1.extend(train_imglist2)\n",
    "x_train = train_imglist1\n",
    "train_tag1.extend(train_tag2)\n",
    "y_train = train_tag1\n",
    "\n",
    "test_imglist1 = test_imglist1.extend(test_imglist2)\n",
    "x_test = test_imglist1\n",
    "test_tag1.extend(test_tag2)\n",
    "y_test = test_tag1\n",
    "'''\n",
    "#y_train = [train_tag1,train_tag2]\n",
    "#y_test = [test_tag1,test_tag2]\n",
    "#print(y_train)\n",
    "#print(y_test)\n",
    "\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(np.array(x_train).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(x_test).shape)\n",
    "print(np.array(y_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 21,137,729\n",
      "Trainable params: 21,137,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import Model\n",
    "#model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "head_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None, classes=2)\n",
    "#model.summary()\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "x = Flatten()(head_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = Model(head_model.input,preds)\n",
    "#top_model.load_weights(top_model_weights_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 924 samples, validate on 236 samples\n",
      "Epoch 1/10\n",
      "924/924 [==============================] - 25s 27ms/step - loss: 0.7082 - acc: 0.5823 - val_loss: 0.6447 - val_acc: 0.6314\n",
      "Epoch 2/10\n",
      "896/924 [============================>.] - ETA: 0s - loss: 0.6644 - acc: 0.6328"
     ]
    }
   ],
   "source": [
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "#print(x_train[1].shape)\n",
    "x_train = x_train.astype('float32')\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#print(np.array(x_train))\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True\n",
    "             )\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        #validation_data=(x_test, y_test),\n",
    "                        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "#Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
